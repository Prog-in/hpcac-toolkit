# ERAD/RS 2024 SCR

This directory contains the scripts and data used in the article "Avaliação da Biblioteca SCR em Instâncias AWS Spot Utilizando a Ferramenta HPC@Cloud" at ERAD/RS 2024.

## Data

The data used in the analysis is available in the `collected_data` folder. There are three folders: `raw`, `mid-processing` and `final`. The `raw` folder contains the raw data collected from the experiments. The `mid-processing` folder contains the data after some processing. The `final` folder contains the data used in the analysis.

## Scripts

This directory contains all the scripts used to configure, capture, post-process the data and generate the figures used in the article. The scripts written in Python use the `numpy` and `matplotlib` libraries. It is recommended to use Python 3.10 or higher to run these scripts.

### Setup Clusters

There are mainly configurations files for setting up the clusters in HPC@Cloud. To configure the clusters, follow the steps below after properly installing [HPC@Cloud](https://github.com/lapesd/hpcac-toolkit):

1. Configure the files in `setup-clusters/cluster_configs`.
2. Copy the folders `setup-clusters/cluster_configs` and `setup-clusters/tasks_configs` and the file `setup-clusters/setup-configs.py` to the root of the [HPC@Cloud](https://github.com/lapesd/hpcac-toolkit) repository;
3. Copy the content of `setup-clusters/Makefile` to the end of the `hpcac-toolkit/Makefile`;
4. Clone the [Jacobi Method](https://github.com/vanderlei-filho/jacobi-method) repository to `hpcac-toolkit/my_files`;
5. Create a folder named `outputs` in `hpcac-toolkit/my_files/`;
6. Copy all the files in `jacobi-configs` to `hpcac-toolkit/my_files/jacobi-method/`;

### Run Experiments

To run the experiments, execute the following command at the root of the [HPC@Cloud](https://github.com/lapesd/hpcac-toolkit) repository:

```bash
make run
```

The experiments will be rub on the clusters configured in the `hpcac-toolkit/cluster_configs` and `hpcac-toolkit/tasks_configs` folders.

The results (raw data) will be saved in the `hpcac-toolkit/results/` folder and in the `hpcac-toolkit/task_results.csv` file.

Copy all the raw data files to the `collected_data/raw` folder. The data should be organized as follows:

```
collected_data/raw
├── exp1-1.txt
├── exp1-2.txt
├── exp1-3.txt
├── exp1-4.txt
├── exp1-5.txt
├── exp2-1.txt
├── ...
└── task_results.csv
```

### Post Processing

There are three scripts used in the post-process the data: `capture.py`, `post_processing.py` and `graphs.py`.

### capture.py

This script captures the raw data generated by the experiments in HPC@Cloud and saves it in `collected_data/mid-processing`. Usage:

```bash
python capture.py <experiment_dir_path>
```

### post_processing.py

This script processes the raw data and generates the data used in the analysis, saving it at `collected_data/final`. Usage:

```bash
python post_processing.py
```

### graphs.py

This script generates the figures used in the article by reading the files in `collected_data/final`. Usage:

```bash
python graphs.py
```
